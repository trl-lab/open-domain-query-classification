{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-13T16:12:25.729669Z",
     "start_time": "2025-11-13T16:12:25.492197Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from common.model import Prompt\n",
    "from common.classification import create_input_instances, create_batch_file, start_batch_job, retrieve_batch_results"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydantic'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcommon\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Prompt\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcommon\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mclassification\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_input_instances, create_batch_file, start_batch_job, retrieve_batch_results\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/cwi/projects/open-domain-query-classification/common/model.py:5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpathlib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m List, Optional, Self\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpydantic\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseModel\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mopenbatch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PromptTemplate, ResponsesRequest\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mPrompt\u001B[39;00m(BaseModel):\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'pydantic'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "20a6df8131997806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load sampled queries\n",
    "queries = pd.read_parquet(\"./data/inputs/sampled_queries.parquet\")\n",
    "\n",
    "# Load classification prompt\n",
    "data_privilege_prompt = Prompt.load(\"./prompts/data_privilege/data_privilege_classification.json\")"
   ],
   "id": "43083aecd4f3abb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create input instances\n",
    "input_instances = create_input_instances(queries[\"query\"], [f\"data_privilege-sample-{index}\" for index, _ in queries.iterrows()])"
   ],
   "id": "536012310bdee9ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create files for batch-jobs\n",
    "batch_file_paths = [\"./batch_jobs/data_privilege/data_privilege_batch_job_1.jsonl\", \"./batch_jobs/data_privilege/data_privilege_batch_job_2.jsonl\", \"./batch_jobs/data_privilege/data_privilege_batch_job_2.jsonl\"]\n",
    "for batch_file_path in batch_file_paths:\n",
    "    create_batch_file(prompt=data_privilege_prompt, instances=input_instances, batch_file_path=batch_file_path)"
   ],
   "id": "a43a29f2be504ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Start batch jobs\n",
    "batch_jobs = [start_batch_job(batch_file_path) for batch_file_path in batch_file_paths]"
   ],
   "id": "7b580246d627edeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the structure of the classification results\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class SchemaDependence(BaseModel):\n",
    "    structural_reference_analysis: str\n",
    "    structural_reference: bool\n",
    "    value_reference_analysis: str\n",
    "    value_reference: Literal[\"True\", \"Obscure\", \"False\"]\n",
    "    container_reference_analysis: str\n",
    "    container_reference: bool"
   ],
   "id": "ebe2a4cbee3330db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Retrieve results from batch jobs; we have to wait until all jobs are completed\n",
    "results = [retrieve_batch_results(batch_job, SchemaDependence) for batch_job in batch_jobs]"
   ],
   "id": "5023830c01b3964c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results_dfs = [pd.DataFrame({\n",
    "        \"id\": result[0],\n",
    "        \"data_privilege_classification\": result[1]\n",
    "    }) for result in results]"
   ],
   "id": "c061ef662683dbdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for df in results_dfs:\n",
    "    df[\"structural_reference\"] = df[\"data_privilege_classification\"].apply(lambda x: x.structural_reference if x is not None else None)\n",
    "    df[\"structural_reference_analysis\"] = df[\"data_privilege_classification\"].apply(lambda x: x.structural_reference_analysis if x is not None else None)\n",
    "    df[\"value_reference\"] = df[\"data_privilege_classification\"].apply(lambda x: x.value_reference if x is not None else None)\n",
    "    df[\"value_reference_analysis\"] = df[\"data_privilege_classification\"].apply(lambda x: x.value_reference_analysis if x is not None else None)\n",
    "    df[\"container_reference\"] = df[\"data_privilege_classification\"].apply(lambda x: x.container_reference if x is not None else None)\n",
    "    df[\"container_reference_analysis\"] = df[\"data_privilege_classification\"].apply(lambda x: x.container_reference_analysis if x is not None else None)"
   ],
   "id": "b3a819122701f66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import List\n",
    "\n",
    "def aggregate_results(dfs: List[pd.DataFrame], columns_to_aggregate: List[str]) -> pd.DataFrame:\n",
    "    full_df = dfs[0][[\"id\"]]\n",
    "    for column in columns_to_aggregate:\n",
    "        full_df[column] = [[r for r in res] for res in zip(*[df[column] for df in dfs])]\n",
    "    return full_df"
   ],
   "id": "d08e58e5afc45f37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "merged_results = aggregate_results(results_dfs, [\"structural_reference\", \"structural_reference_analysis\", \"value_reference\", \"value_reference_analysis\", \"container_reference\", \"container_reference_analysis\"])",
   "id": "3aee2a7c72a361c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "merged_results_deviations = merged_results[(merged_results[\"structural_reference\"].apply(lambda x: len(set(x))) != 1) | (merged_results[\"value_reference\"].apply(lambda x: len(set(x))) != 1) | (merged_results[\"container_reference\"].apply(lambda x: len(set(x))) != 1)]\n",
    "\n",
    "queries_b4 = queries.merge(merged_results_deviations, on=\"id\", how=\"inner\")\n",
    "\n",
    "b4_input_instances = create_input_instances(queries_b4[\"query\"], queries_b4[\"id\"])\n",
    "\n",
    "b4_file_path = \"./batch_jobs/data_privilege/data_privilege_batch_job_4.jsonl\"\n",
    "create_batch_file(prompt=data_privilege_prompt, instances=b4_input_instances, batch_file_path=b4_file_path)\n",
    "b4 = start_batch_job(b4_file_path)"
   ],
   "id": "bfe5df6d8705c4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "b4_results = retrieve_batch_results(b4, SchemaDependence)\n",
    "b4_res_df = pd.DataFrame({\n",
    "        \"id\": b4_results[0],\n",
    "        \"data_privilege_classification\": b4_results[1]\n",
    "    })"
   ],
   "id": "407cb74b1e399c81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "b4_merge = merged_results.merge(b4_res_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "b4_merge[\"structural_reference\"] = b4_merge.apply(lambda row: row[\"structural_reference\"] + [row[\"data_privilege_classification\"].structural_reference], axis=1)\n",
    "b4_merge[\"value_reference\"] = b4_merge.apply(lambda row: row[\"value_reference\"] + [row[\"data_privilege_classification\"].value_reference], axis=1)\n",
    "b4_merge[\"container_reference\"] = b4_merge.apply(lambda row: row[\"container_reference\"] + [row[\"data_privilege_classification\"].container_reference], axis=1)\n",
    "\n",
    "cols = [\"structural_reference\", \"value_reference\", \"container_reference\"]\n",
    "\n",
    "# ensure unique ids in b4_merge (keep last if duplicates)\n",
    "b4_indexed = b4_merge.drop_duplicates(subset=\"id\", keep=\"last\").set_index(\"id\")\n",
    "\n",
    "# index merged_results by id, update only the listed columns from b4_merge\n",
    "merged_indexed = merged_results.set_index(\"id\")\n",
    "merged_indexed.update(b4_indexed[cols])"
   ],
   "id": "b2374659d6aecbb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def voting(l):\n",
    "    res = {}\n",
    "    for item in l:\n",
    "        res[item] = res.get(item, 0) + 1\n",
    "    return res\n",
    "\n",
    "def check_voting_majority(voting_dict, threshold):\n",
    "    for key, count in voting_dict.items():\n",
    "        if count >= threshold:\n",
    "            return key\n",
    "    return None"
   ],
   "id": "9c892e8649ce0b02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "structural_votings = merged_indexed[\"structural_reference\"].apply(lambda x: voting(x))\n",
    "value_votings = merged_indexed[\"value_reference\"].apply(lambda x: voting(x))\n",
    "container_votings = merged_indexed[\"container_reference\"].apply(lambda x: voting(x))\n",
    "b5_mask = structural_votings.apply(lambda x: check_voting_majority(x, 3) is None) | value_votings.apply(lambda x: check_voting_majority(x, 3) is None) | container_votings.apply(lambda x: check_voting_majority(x, 3) is None)\n",
    "\n",
    "b5_queries = queries.set_index(\"id\")[b5_mask]\n",
    "\n",
    "b5_input_instances = create_input_instances(b5_queries[\"query\"], b5_queries.index)\n",
    "b5_file_path = \"./batch_jobs/data_privilege/data_privilege_batch_job_5.jsonl\"\n",
    "create_batch_file(prompt=data_privilege_prompt, instances=b5_input_instances, batch_file_path=b5_file_path)\n",
    "b5 = start_batch_job(b5_file_path)"
   ],
   "id": "1f18d328dbe374c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "b5_results = retrieve_batch_results(b5, SchemaDependence)\n",
    "b5_res_df = pd.DataFrame({\n",
    "        \"id\": b5_results[0],\n",
    "        \"data_privilege_classification\": b5_results[1]\n",
    "    })\n",
    "b5_merge = merged_indexed.merge(b5_res_df, on=\"id\", how=\"inner\")"
   ],
   "id": "8bfab6a2728f571e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "b5_merge[\"structural_reference\"] = b5_merge.apply(lambda row: row[\"structural_reference\"] + [row[\"data_privilege_classification\"].structural_reference], axis=1)\n",
    "b5_merge[\"value_reference\"] = b5_merge.apply(lambda row: row[\"value_reference\"] + [row[\"data_privilege_classification\"].value_reference], axis=1)\n",
    "b5_merge[\"container_reference\"] = b5_merge.apply(lambda row: row[\"container_reference\"] + [row[\"data_privilege_classification\"].container_reference], axis=1)"
   ],
   "id": "ad608900b1c611ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cols = [\"structural_reference\", \"value_reference\", \"container_reference\"]\n",
    "\n",
    "# ensure unique ids in b4_merge (keep last if duplicates)\n",
    "b5_indexed = b5_merge.drop_duplicates(subset=\"id\", keep=\"last\").set_index(\"id\")\n",
    "\n",
    "# index merged_results by id, update only the listed columns from b4_merge\n",
    "# merged_indexed = merged_indexed.set_index(\"id\")\n",
    "merged_indexed.update(b5_indexed[cols])"
   ],
   "id": "38cde7cd3b1cc8bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "merged_indexed[\"structural_reference_final\"] = merged_indexed[\"structural_reference\"].apply(lambda x: check_voting_majority(voting(x), 3))\n",
    "merged_indexed[\"value_reference_final\"] = merged_indexed[\"value_reference\"].apply(lambda x: check_voting_majority(voting(x), 3))\n",
    "merged_indexed[\"container_reference_final\"] = merged_indexed[\"container_reference\"].apply(lambda x: check_voting_majority(voting(x), 3))"
   ],
   "id": "d92a9c82814832a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results = queries.merge(merged_indexed, left_on=\"id\", right_index=True, how=\"inner\")",
   "id": "9be8ad987e342525"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results.to_parquet(\"./data/outputs/data_privilege/data_privilege_classification.parquet\", index=False)",
   "id": "874f41f4383780d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
